{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957ab311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3250.169] global /mnt/onetb/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/mnt/onetb/yuuka/lumen/Lumen_228.tif'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0-pre) /mnt/onetb/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m img1 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(img1_full, (\u001b[38;5;241m950\u001b[39m, \u001b[38;5;241m950\u001b[39m))\n\u001b[1;32m    124\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(img2_full, (\u001b[38;5;241m950\u001b[39m, \u001b[38;5;241m950\u001b[39m))\n\u001b[0;32m--> 126\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43maffine_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m M \u001b[38;5;241m=\u001b[39m compose_affine_maps(prev_map, M)\n\u001b[1;32m    128\u001b[0m prev_map \u001b[38;5;241m=\u001b[39m M\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36maffine_alignment\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maffine_alignment\u001b[39m(img1, img2):\n\u001b[0;32m---> 27\u001b[0m     img1_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     img2_gray \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(img2, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     30\u001b[0m     empty_array_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(img1_gray\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0-pre) /mnt/onetb/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "filedir = '/mnt/onetb/yuuka/lumen/'\n",
    "savedir = filedir\n",
    "\n",
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv.resize(image, dim, interpolation=inter)\n",
    "\n",
    "def affine_alignment(img1, img2):\n",
    "\n",
    "    img1_gray = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    empty_array_1 = np.zeros(img1_gray.shape[:2], dtype=np.uint8)\n",
    "    empty_array_2 = np.zeros(img2_gray.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    row1, col1 = img1_gray.shape\n",
    "    row2, col2 = img2_gray.shape\n",
    "\n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    kp1, d1 = sift.detectAndCompute(img1_gray, mask = None)\n",
    "    kp2, d2 = sift.detectAndCompute(img2_gray, mask = None)\n",
    "\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(d1, d2, k = 2)\n",
    "\n",
    "    ratio = 0.8\n",
    "\n",
    "    good_matches = []\n",
    "    for i, j in matches:\n",
    "        if i.distance < j.distance * ratio:\n",
    "            good_matches.append([i])\n",
    "\n",
    "    source = np.float32([kp1[m[0].queryIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "    destination = np.float32([kp2[m[0].trainIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "\n",
    "    source = source\n",
    "    destination = destination\n",
    "\n",
    "    M, mask = cv.estimateAffine2D(source, destination)\n",
    "    \n",
    "    M[0,2] *= 8\n",
    "    M[1,2] *= 8\n",
    "\n",
    "    return M\n",
    "\n",
    "#have N images\n",
    "#find map between neighbouring images M from i+1 to i image\n",
    "#apply maps using compositions\n",
    "#can also have map aligned to previous image, this method sucks \n",
    "#deformations in previous images lead to even worse deformations in new images\n",
    "#also it seems to be worse when doing masking on deformed images\n",
    "#instead, store array of all transformations\n",
    "#at the end, apply transformations to both images and masks\n",
    "#save the masks, save the images\n",
    "\n",
    "def load_img(index):\n",
    "    \n",
    "    img = cv.imread(filedir + 'Lumen_' + str(index) + '.tif')\n",
    "    top, bottom, left, right = 47, 46, 193, 194\n",
    "    img = cv.copyMakeBorder(img, top, bottom, left, right, borderType = cv.BORDER_CONSTANT)\n",
    "\n",
    "    return img\n",
    "\n",
    "def compose_affine_maps(M1, M2):\n",
    "    #composition of M2 circ M1\n",
    "\n",
    "    M1_new = np.zeros((3,3))\n",
    "    M2_new = np.zeros((3,3))\n",
    "\n",
    "    M1_new[0:2, :] = M1\n",
    "    M1_new[2,2] = 1\n",
    "    M2_new[0:2, :] = M2\n",
    "    M2_new[2,2] = 1\n",
    "\n",
    "    return np.matmul(M1_new, M2_new)[0:2, :]\n",
    "\n",
    "start = 167\n",
    "end = 238\n",
    "        \n",
    "prev_map = None\n",
    "        \n",
    "for i in range(start, end):\n",
    "    \n",
    "    if i == start:\n",
    "        \n",
    "        img1_full = load_img(i)\n",
    "        img2_full = load_img(i + 1)\n",
    "\n",
    "        img1 = cv.resize(img1_full, (950, 950))\n",
    "        img2 = cv.resize(img2_full, (950, 950))\n",
    "        \n",
    "        M = affine_alignment(img2, img1)\n",
    "        \n",
    "        prev_map = M\n",
    "        \n",
    "        dst = cv.warpAffine(img2_full, M, (img2_full.shape[1], img2_full.shape[0]))\n",
    "        cv.imwrite(savedir + f'lumen_affine_{i+1}.tif', dst)\n",
    "        print(i)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        img1_full = img2_full\n",
    "        img2_full = load_img(i + 1)\n",
    "\n",
    "        img1 = cv.resize(img1_full, (950, 950))\n",
    "        img2 = cv.resize(img2_full, (950, 950))\n",
    "\n",
    "        M = affine_alignment(img2, img1)\n",
    "        M = compose_affine_maps(prev_map, M)\n",
    "        prev_map = M\n",
    "        \n",
    "        dst = cv.warpAffine(img2_full, M, (img2_full.shape[1], img2_full.shape[0]))\n",
    "        cv.imwrite(savedir + f'lumen_affine_{i+1}.tif', dst)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2635fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
